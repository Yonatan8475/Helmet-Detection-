# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1INOGrqeS6D1i5uzzHqvFKV1KNz8D1CiL
"""

!pip install ultralytics
!pip install matplotlib
!pip install pyyaml



import os
import zipfile
import random
from collections import Counter
import yaml
import matplotlib.pyplot as plt
from ultralytics import YOLO
from google.colab import files
import cv2
import glob
import random

"""Facilitates uploading a ZIP file in Google Colab, extracting its contents to a specified directory, and returning the path to the extracted dataset. It also displays a confirmation message and lists the files and folders inside the destination directory."""

def upload_and_extract_zip_colab(extract_to="/content/dataset"):
    """
    Prompts the user to upload a ZIP file in Google Colab and extracts it to the specified directory.

    Parameters:
        extract_to (str): Path where the ZIP file will be extracted. Default is '/content/dataset'.

    Returns:
        str: The path to the extracted dataset directory.
    """
    # Step 1: Prompt user to upload a ZIP file
    print("Please upload your dataset ZIP file:")
    uploaded = files.upload()  # Opens the file upload dialog in Google Colab

    # Step 2: Identify the uploaded ZIP file name
    zip_filename = list(uploaded.keys())[0]

    # Step 3: Create the destination directory if it doesn't exist
    os.makedirs(extract_to, exist_ok=True)

    # Step 4: Extract the contents of the ZIP file
    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

    # Step 5: Print and return the dataset path
    print(f"✅ File '{zip_filename}' successfully extracted to '{extract_to}'.")
    print("Files and Folders:", os.listdir(extract_to))
    return extract_to

""" Define the extraction directory for a dataset in Colab, extract the contents of a ZIP file, and display the path to the extracted dataset directory."""

# Define the extraction directory (you can adjust this)
dataset_path = upload_and_extract_zip_colab("/content/dataset")

# Now `dataset_path` contains the path to the extracted dataset directory
print("Dataset Directory:", dataset_path)

"""Structured dataset and retrieves important metadata (e.g., class names) to facilitate further processing

This code performs the following tasks:

1. **Define the `load_yaml` Function:**
   - The `load_yaml` function is designed to open a YAML file from a specified path and load its contents into a format that Python can work with.
   - It uses the `yaml.safe_load()` method, which ensures that the YAML file is read in a safe and reliable way.

2. **Load the YAML File:**
   - After defining the function, it is used to load a YAML configuration file located at `yaml_path`. This file typically contains structured data or settings relevant to the program.

3. **Display the Loaded Data:**
   - The contents of the loaded YAML file are displayed using the `display()` function to verify its structure and ensure that the data has been loaded correctly.

**Purpose of the Code:**
This code is useful for reading and working with configuration data stored in a YAML file. It ensures that the file's contents are safely loaded and available for use in tasks such as training models or organizing dataset metadata.
"""

def load_yaml(yaml_path):
    """
    Loads the YAML configuration file.
    """
    with open(yaml_path, "r") as file:
        data_yaml = yaml.safe_load(file)
    return data_yaml
data_yaml = load_yaml(yaml_path)
display(data_yaml)
zip_path = "/content/Hard Hat Workers.v2-raw_75-25_traintestsplit.yolov8.zip"
extract_to = "/content/dataset"
yaml_path = os.path.join(extract_to, "data.yaml")
labels_path = os.path.join(extract_to, "train", "labels")
train_images_path = os.path.join(extract_to, "train", "images")
val_images_path = os.path.join(extract_to, "test", "images")
test_images_path = os.path.join(extract_to, "test", "images")


# Load YAML configuration
data_yaml = load_yaml(yaml_path)
class_names = data_yaml["names"]



"""## Counting Class Distribution

This code counts how many times each class appears in the dataset by reading label files. It processes each file, extracts the class IDs, converts them to class names, and keeps track of their counts. Finally, it prints the distribution of classes in the dataset.


"""

def count_class_distribution(labels_path, class_names):
    """
    Counts the distribution of each class in the dataset.
    """
    class_counts = Counter()
    for label_file in os.listdir(labels_path):
        with open(os.path.join(labels_path, label_file), "r") as f:
            for line in f:
                class_id = int(line.split()[0])
                class_counts[class_names[class_id]] += 1
    return class_counts
initial_distribution = count_class_distribution(labels_path, class_names)
print("Initial Class Distribution:", initial_distribution)

"""## Plotting Class Distribution

This code creates a bar chart to visually represent the class distribution in the dataset. It takes the class counts and a title as input, and plots the number of instances for each class using a labeled and clear layout.

"""

def plot_class_distribution(class_counts, title):
    """
    Plots the class distribution.
    """
    plt.figure(figsize=(10, 5))
    plt.bar(class_counts.keys(), class_counts.values(), color="skyblue")
    plt.xlabel("Class Name")
    plt.ylabel("Number of Instances")
    plt.title(title)
    plt.xticks(rotation=45)
    plt.show()
plot_class_distribution(initial_distribution, "Initial Class Distribution in Training Data")

"""## Balancing the Dataset

This code balances the dataset by reducing the number of instances in the majority class (downsampling). It works as follows:

1. Reads label files from the dataset to identify and process annotations.
2. Removes annotations of the majority class (`person`) and calculates class distribution after removal.
3. Selectively downsamples the `helmet` class to match the count of the `head` class.
4. Updates the label files with the adjusted annotations.
5. Returns the final balanced class distribution and displays it using a bar chart.

This ensures that the dataset has a more even representation of classes, reducing bias during model training.

"""

def balance_dataset(labels_path, class_names):
    """
    Balances the dataset by downsampling the majority class.
    """
    annotations = {}
    helmet_records = []

    for label_file in os.listdir(labels_path):
        file_path = os.path.join(labels_path, label_file)
        with open(file_path, "r") as f:
            lines = f.readlines()

        new_lines = []
        for line in lines:
            parts = line.split()
            if not parts:
                continue
            class_id = int(parts[0])
            if class_names[class_id] == "person":
                continue
            new_lines.append(line)
            if class_names[class_id] == "helmet":
                helmet_records.append((label_file, len(new_lines) - 1))

        annotations[label_file] = new_lines

    dist_after_removal = Counter()
    for lines in annotations.values():
        for line in lines:
            parts = line.split()
            if parts:
                class_id = int(parts[0])
                dist_after_removal[class_names[class_id]] += 1

    helmet_count = dist_after_removal["helmet"]
    head_count = dist_after_removal["head"]
    target = head_count

    if target > len(helmet_records):
        print("Warning: Target exceeds available helmet labels!")
        target = len(helmet_records)
    selected_helmet = set(random.sample(helmet_records, target))

    for label_file, lines in annotations.items():
        filtered_lines = []
        for idx, line in enumerate(lines):
            parts = line.split()
            if not parts:
                continue
            class_id = int(parts[0])
            if class_names[class_id] == "helmet":
                if (label_file, idx) in selected_helmet:
                    filtered_lines.append(line)
            else:
                filtered_lines.append(line)
        annotations[label_file] = filtered_lines

    for label_file, lines in annotations.items():
        file_path = os.path.join(labels_path, label_file)
        with open(file_path, "w") as f:
            f.writelines(lines)

    final_distribution = Counter()
    for label_file in os.listdir(labels_path):
        file_path = os.path.join(labels_path, label_file)
        with open(file_path, "r") as f:
            for line in f:
                parts = line.split()
                if parts:
                    class_id = int(parts[0])
                    final_distribution[class_names[class_id]] += 1

    return final_distribution
final_distribution = balance_dataset(labels_path, class_names)
print("Final Class Distribution:", final_distribution)
plot_class_distribution(final_distribution, "Balanced Class Distribution in Training Data")

"""## Updating the YAML Configuration

This code updates a YAML configuration file with new dataset paths and class names. It performs the following:

1. Creates a new YAML content structure with:
   - Paths for training, validation, and test datasets.
   - The number of classes (`nc`) and their names (`names`).

2. Writes the updated content back to the specified YAML file (`yaml_path`).

3. Prints a confirmation message upon successful update.

This ensures that the configuration file is updated to match the current dataset structure.

"""

def update_yaml(yaml_path, train_path, val_path, test_path, class_names):
    """
    Updates the YAML configuration file with new paths and class names.
    """
    new_yaml_content = {
        "train": train_path,
        "val": val_path,
        "test": test_path,
        "nc": len(class_names),
        "names": class_names
    }
    with open(yaml_path, "w") as file:
        yaml.dump(new_yaml_content, file, default_flow_style=False)
    print(f"✅ Updated {yaml_path} successfully!")
updated_yaml_path = "my_data.yaml"
updated_class_names = ["head", "helmet"]
update_yaml(updated_yaml_path, train_images_path, val_images_path, test_images_path, updated_class_names)

"""## Training the YOLOv8 Model

This code trains a YOLOv8 model using the specified dataset and parameters. Here's what it does:

1. **Model Initialization:**  
   - The YOLO model is loaded using the pre-trained weights from `model_path` (default is "yolov8n.pt").

2. **Training Configuration:**  
   - The `train` method is called with various training parameters, including:
     - Number of epochs (`epochs=200`)
     - Image size (`imgsz=1536`)
     - Batch size (`batch=16`)
     - Early stopping patience (`patience=30`)
     - Learning rate (`lr0=1e-4`)
     - Optimizer (`Adam`) and augmentation techniques (e.g., `mixup`, `degrees`, `shear`)
     - Cosine learning rate scheduler (`cos_lr=True`).

3. **Training Execution:**  
   - The model trains on the dataset specified in the `data_yaml` file using the given parameters.

4. **Completion Message:**  
   - A confirmation message is printed once training is completed.

The result is a YOLOv8 model trained and ready for evaluation or deployment.

"""

def train_yolo(data_yaml, model_path="yolov8n.pt", epochs=50):
    """
    Trains the YOLOv8 model using the provided data and parameters.
    """

    model = YOLO(model_path)
    model.train(
        data=data_yaml,
        epochs=100,            # Total number of training epochs
        imgsz=1536,            # Image size
        batch=16,              # Batch size
        patience=10,           # Early stopping patience
        freeze=10,             # Number of layers to freeze
        lr0=1e-4,              # Initial learning rate
        optimizer='Adam',      # Optimizer choice
        mixup=0.2,             # MixUp augmentation probability
        degrees=10.0,          # Rotation augmentation
        shear=2.0,             # Shear augmentation
        cos_lr=True            # Use cosine learning rate scheduler
)

    print("✅ Model training completed.")
    return model

"""## Main Function Overview

This `main` function orchestrates the workflow for training, validating, testing, and exporting a YOLOv8 model. Here's what it does:

1. **Train and Validate the Model:**
   - Calls the `train_yolo` function to train the YOLOv8 model using the specified YAML configuration file and parameters.
   - Validates the trained model by running `model.val()` to check its performance on the validation dataset.

2. **Test the Model:**
   - Uses `model.predict` to make predictions on new test images, saving the results for later review.

3. **Export the Model:**
   - Exports the trained YOLOv8 model in two formats:
     - `onnx` (Open Neural Network Exchange) for interoperability.
     - `engine` format, possibly for deployment on platforms like TensorRT.

4. **Execution:**
   - If the script is run directly (`__name__ == "__main__"`), the `main` function is executed.

This function integrates the key stages of the model's lifecycle, from training to deployment.

"""

def main():
    # Validate the model
    model = train_yolo(updated_yaml_path, model_path="yolov8n.pt", epochs=100)
    model.val()

    # Test on new images
    results = model.predict(source=test_images_path, save=True)

    # Export the model (Optional for Deployment)
    model.export(format="onnx")
    model.export(format="engine")

if __name__ == "__main__":
    main()

# Save the model
model.save('best_model.pt')



"""## Displaying an Image

This code loads an image from a given file path and displays it using Matplotlib. Here's how it works:

1. **Image Loading:**
   - It uses OpenCV to load the image from `image_path`.

2. **Error Handling:**
   - If the image fails to load, it prints an error message and exits.

3. **Color Conversion:**
   - Converts the image from BGR format (used by OpenCV) to RGB format (used by Matplotlib).

4. **Image Display:**
   - Displays the image in a Matplotlib plot with axes hidden for
"""

def display_image(image_path):
    """
    Loads an image from the specified path and displays it using Matplotlib.

    Args:
        image_path (str): The file path to the image.

    Returns:
        None
    """
    # Load the image using OpenCV
    img = cv2.imread(image_path)

    # Check if the image was successfully loaded
    if img is None:
        print(f"Error: Unable to load image at {image_path}")
        return

    # Convert the image from BGR (OpenCV format) to RGB (Matplotlib format)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Display the image using Matplotlib
    plt.figure(figsize=(10, 5))
    plt.imshow(img_rgb)
    plt.axis("off")  # Hide axis
    plt.show()
# Specify the path to your image
image_path = "runs/detect/train/results.png"

# Call the function to display the image
display_image(image_path)

"""## Performing Inference

Inference refers to the process of using a trained model to make predictions or detect patterns in new, unseen data. This is a critical stage in deploying machine learning models and testing their practical applications.

### Key Steps in Inference:
1. **Input Data:** Provide new data (e.g., images or text) to the trained model for evaluation.
2. **Model Predictions:** The model processes the input data and generates predictions or insights based on its learned knowledge.
3. **Analysis and Output:** Interpret and visualize the results to evaluate the model's performance or extract valuable information.

### In the Context of This Code:
The provided code demonstrates how to perform inference with a trained YOLO model:
- It uses the `train_yolo` function to train and validate the model.
- The `model.predict` function applies the trained model to a set of new images (test data).
- Outputs like predicted labels or bounding boxes are generated and saved for review.
- Optionally, the model is exported in formats such as `onnx` or `engine` for deployment.

This ensures the model's capability to generalize to unseen data and its readiness for real-world applications.

"""

def load_class_names(yaml_path):
    """
    Load class names from a YAML file.

    Args:
        yaml_path (str): Path to the YAML file containing class names.

    Returns:
        list: List of class names.
    """
    with open(yaml_path, "r") as file:
        data_yaml = yaml.safe_load(file)
    return data_yaml.get("names", [])

def read_labels(label_path):
    """
    Read YOLO format labels from a text file.

    Args:
        label_path (str): Path to the label file.

    Returns:
        list: List of tuples containing class_id, x_center, y_center, width, height.
    """
    labels = []
    try:
        with open(label_path, "r") as file:
            lines = file.readlines()
        for line in lines:
            parts = line.strip().split()
            class_id = int(parts[0])
            x_center, y_center, width, height = map(float, parts[1:])
            labels.append((class_id, x_center, y_center, width, height))
    except FileNotFoundError:
        print(f"Label file not found: {label_path}")
    return labels

def draw_boxes(image, boxes, color, class_names):
    """
    Draw bounding boxes on an image.

    Args:
        image (numpy.ndarray): The image on which to draw.
        boxes (list): List of bounding boxes in YOLO format.
        color (tuple): Color for the bounding boxes.
        class_names (list): List of class names.

    Returns:
        numpy.ndarray: Image with bounding boxes drawn.
    """
    h, w, _ = image.shape
    for box in boxes:
        class_id, x_center, y_center, width, height = box
        if class_id < 0 or class_id >= len(class_names):
            print(f"Skipping invalid class ID: {class_id}")
            continue
        x1 = int((x_center - width / 2) * w)
        y1 = int((y_center - height / 2) * h)
        x2 = int((x_center + width / 2) * w)
        y2 = int((y_center + height / 2) * h)
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(image, class_names[class_id], (x1, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    return image

def visualize_predictions(model_path, test_images_path, test_labels_path, yaml_path, num_images=5):
    """
    Visualize ground truth and predicted bounding boxes for test images.

    Args:
        model_path (str): Path to the trained YOLO model.
        test_images_path (str): Directory containing test images.
        test_labels_path (str): Directory containing test labels.
        yaml_path (str): Path to the YAML file with class names.
        num_images (int): Number of images to visualize.
    """
    # Load YOLO model
    model = YOLO(model_path)

    # Load class names
    class_names = load_class_names(yaml_path)
    print("Loaded class names:", class_names)

    # Get test images
    test_images = glob.glob(os.path.join(test_images_path, "*.jpg"))
    if not test_images:
        print(f"No images found in {test_images_path}")
        return

    # Run inference
    results = model.predict(source=test_images[:num_images], save=False)

    # Iterate over the selected number of images
    for img_path, result in zip(test_images[:num_images], results):
        img_name = os.path.basename(img_path)
        label_path = os.path.join(test_labels_path, img_name.replace(".jpg", ".txt"))

        # Read image
        img = cv2.imread(img_path)
        if img is None:
            print(f"Failed to read image: {img_path}")
            continue
        img_gt = img.copy()
        img_pred = img.copy()

        # Read ground truth labels
        gt_boxes = read_labels(label_path)
        if gt_boxes:
            img_gt = draw_boxes(img_gt, gt_boxes, (0, 255, 0), class_names)  # Green for GT

        # Get predictions
        pred_boxes = []
        for box in result.boxes.data:
            x1, y1, x2, y2, conf, class_id = box.tolist()
            class_id = int(class_id)
            if class_id < 0 or class_id >= len(class_names):
                print(f"Skipping invalid class ID: {class_id}")
                continue
            x_center = (x1 + x2) / 2 / img.shape[1]
            y_center = (y1 + y2) / 2 / img.shape[0]
            width = (x2 - x1) / img.shape[1]
            height = (y2 - y1) / img.shape[0]
            pred_boxes.append((class_id, x_center, y_center, width, height))

        img_pred = draw_boxes(img_pred, pred_boxes, (255, 0, 0), class_names)  # Red for Predictions

        # Show images side by side
        fig, axs = plt.subplots(1, 2, figsize=(10, 5))
        axs[0].imshow(cv2.cvtColor(img_gt, cv2.COLOR_BGR2RGB))
        axs[0].set_title("Ground Truth")
        axs[0].axis("off")

        axs[1].imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB))
        axs[1].set_title("Predictions")
        axs[1].axis("off")

        plt.show()

# Example usage
if __name__ == "__main__":
    visualize_predictions(
        model_path="runs/detect/train/weights/best.pt",
        test_images_path="dataset/test/images",
        test_labels_path="dataset/test/labels",
        yaml_path="my_data.yaml",
        num_images=10
    )

from google.colab import drive
drive.mount('/content/drive')

import shutil

# Define source and destination paths
source_path = 'runs/detect/train/weights/best.pt'
destination_path = '/content/drive/My Drive/ColabModels/best_model.pt'

# Create the destination directory if it doesn't exist
os.makedirs(os.path.dirname(destination_path), exist_ok=True)

# Copy the model file to Google Drive
shutil.copy(source_path, destination_path)